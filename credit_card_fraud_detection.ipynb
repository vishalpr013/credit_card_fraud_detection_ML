{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('creditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class = 0 -- Transanction is not fraud\n",
    "\n",
    "Class = 1 -- Transanction is fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    284807.000000\n",
       "mean         88.349619\n",
       "std         250.120109\n",
       "min           0.000000\n",
       "25%           5.600000\n",
       "50%          22.000000\n",
       "75%          77.165000\n",
       "max       25691.160000\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud Transactions:  492\n",
      "Normal Transactions:  284315\n"
     ]
    }
   ],
   "source": [
    "fraud = len(df[df['Class']==1])\n",
    "genuine = len(df[df['Class']==0])\n",
    "print('Fraud Transactions: ',fraud)\n",
    "print('Normal Transactions: ',genuine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlUAAAHHCAYAAACWQK1nAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9jklEQVR4nO3de1gV9d7//9cC5aC4QBFBkgRPKWVaqEiWhyIxMTOpHW63W02zDDQl85Dmqbot+5pmnrKuHW53ltqdusPSDE+VmIqRh8JdJllbAVNhKSkgzO+PfsztEkzBUUSej+uaK2c+7/nMe5YHXs2aNctmGIYhAAAAXBGXym4AAADgRkCoAgAAsAChCgAAwAKEKgAAAAsQqgAAACxAqAIAALAAoQoAAMAChCoAAAALEKoAAAAsQKgCIElKTEyUzWZTRkbGdddH165d1bVr12veS2UdtzyysrL0yCOPyNfXVzabTXPmzLkmx+3atatuu+02S+cMDg7WoEGDLJ0TuJYIVcANqnfv3qpVq5ZOnTp10Zr+/fvLzc1Nx48fv4adXV++++47TZ06tdLDZEWNHj1a69ev14QJE7R06VL16NHjorU2m03x8fHXsDugeiFUATeo/v3768yZM1q1alWZ47///rvWrFmjHj16yNfXVwMGDNCZM2fUuHHja9zppX322Wf67LPPrsrc3333naZNm1ZmqLqax7XKxo0b9dBDD2nMmDH629/+ppYtW1Z2S0C1RagCblC9e/dWnTp1tGzZsjLH16xZo7y8PPXv31+S5OrqKg8PD9lstmvZ5mVxc3OTm5tbtTlueWRnZ8vHx6ey2wAgQhVww/L09FTfvn2VnJys7OzsUuPLli1TnTp11Lt3b0ll38u0a9cuRUVFqX79+vL09FRISIgef/xxc3zz5s2y2WzavHmz09wZGRmy2WxKTEw0t+3Zs0eDBg1SkyZN5OHhoYCAAD3++OOX9dbjhfc2BQcHy2azlbmU9PLzzz/r6aef1i233CJPT0/5+vrq0UcfdTq/xMREPfroo5Kkbt26lZqjrHuqsrOzNWTIEPn7+8vDw0Nt2rTRkiVLyjz///f//p8WL16spk2byt3dXe3bt9fOnTsveb6S9NNPP+nRRx9VvXr1VKtWLXXs2FFr16516t1ms8kwDM2fP9/s/UqtWbNG0dHRCgwMlLu7u5o2baoXX3xRRUVFZdanpqbqrrvuMv98LFq0qFRNfn6+pkyZombNmsnd3V1BQUEaO3as8vPz/7SXwsJCTZs2Tc2bN5eHh4d8fX119913a8OGDVd8nsDVUKOyGwBw9fTv319LlizRihUrnO6lOXHihNavX69+/frJ09OzzH2zs7PVvXt3+fn5afz48fLx8VFGRoY++uijCvWyYcMG/fTTTxo8eLACAgK0f/9+LV68WPv379f27dvLFQjmzJmj06dPO22bPXu20tLS5OvrK0nauXOntm3bptjYWDVq1EgZGRlauHChunbtqu+++061atVS586dNXLkSM2dO1fPP/+8WrVqJUnmfy905swZde3aVT/++KPi4+MVEhKilStXatCgQcrJydEzzzzjVL9s2TKdOnVKTz75pGw2m2bOnKm+ffvqp59+Us2aNS96fllZWbrrrrv0+++/a+TIkfL19dWSJUvUu3dvffjhh3r44YfVuXNnLV26VAMGDND999+vv//975f9+v2ZxMREeXl5KSEhQV5eXtq4caMmT54sh8Oh1157zan25MmT6tmzp/7yl7+oX79+WrFihYYPHy43NzczfBcXF6t379768ssvNWzYMLVq1Up79+7V7Nmz9Z///EerV6++aC9Tp07VjBkzNHToUHXo0EEOh0O7du3S7t27df/991tyvoClDAA3rHPnzhkNGzY0IiIinLYvWrTIkGSsX7/e3Pbuu+8akoxDhw4ZhmEYq1atMiQZO3fuvOj8mzZtMiQZmzZtctp+6NAhQ5Lx7rvvmtt+//33Uvu///77hiRj69atF+3DMAyjS5cuRpcuXS7ax4oVKwxJxvTp0//0eCkpKYYk45///Ke5beXKlWWeQ1nHnTNnjiHJ+Ne//mVuKygoMCIiIgwvLy/D4XA4nb+vr69x4sQJs3bNmjWGJOPjjz++6LkYhmGMGjXKkGR88cUX5rZTp04ZISEhRnBwsFFUVGRul2TExcX96XzlqS3rdXvyySeNWrVqGWfPnjW3denSxZBkzJo1y9yWn59vtG3b1mjQoIFRUFBgGIZhLF261HBxcXE6F8P4vz+DX331lbmtcePGxsCBA831Nm3aGNHR0Zd1bsD1gLf/gBuYq6urYmNjlZKS4vS217Jly+Tv76/77rvvovuW3KeTlJSkwsLCK+7l/CtiZ8+e1W+//aaOHTtKknbv3l3heb/77js9/vjjeuihhzRp0qQyj1dYWKjjx4+rWbNm8vHxqfDxPvnkEwUEBKhfv37mtpo1a2rkyJE6ffq0tmzZ4lT/2GOPqW7duub6PffcI+mPt/YudZwOHTro7rvvNrd5eXlp2LBhysjI0HfffVeh/i/H+a/bqVOn9Ntvv+mee+7R77//rvT0dKfaGjVq6MknnzTX3dzc9OSTTyo7O1upqamSpJUrV6pVq1Zq2bKlfvvtN3O59957JUmbNm26aC8+Pj7av3+/fvjhBytPEbhqCFXADa7kRvSSG9Z//fVXffHFF4qNjZWrq+tF9+vSpYtiYmI0bdo01a9fXw899JDefffdS94HczEnTpzQM888I39/f3l6esrPz08hISGSpNzc3ArN6XA41LdvX91000365z//6fQW4pkzZzR58mQFBQXJ3d1d9evXl5+fn3Jycip8vJ9//lnNmzeXi4vzP50lbxf+/PPPTttvvvlmp/WSgHXy5MlLHueWW24ptf1ix7HS/v379fDDD8vb21t2u11+fn7629/+Jqn071NgYKBq167ttK1FixaSZIb4H374Qfv375efn5/TUlJX1v1+JaZPn66cnBy1aNFCrVu31nPPPac9e/ZYdaqA5binCrjBhYWFqWXLlnr//ff1/PPP6/3335dhGGbYuhibzaYPP/xQ27dv18cff6z169fr8ccf16xZs7R9+3Z5eXld9D6osm5q/stf/qJt27bpueeeU9u2beXl5aXi4mL16NFDxcXFFTq3QYMG6ciRI9qxY4fsdrvT2IgRI/Tuu+9q1KhRioiIkLe3t2w2m2JjYyt8vPK6WGg1DOOaHL+8cnJy1KVLF9ntdk2fPl1NmzaVh4eHdu/erXHjxlXodSsuLlbr1q31+uuvlzkeFBR00X07d+6sgwcPas2aNfrss8/0zjvvaPbs2Vq0aJGGDh1a7l6Aq41QBVQD/fv31wsvvKA9e/Zo2bJlat68udq3b39Z+3bs2FEdO3bUyy+/rGXLlql///764IMPNHToUPPKS05OjtM+F15JOXnypJKTkzVt2jRNnjzZ3H4lb+u88sorWr16tT766KMyn8304YcfauDAgZo1a5a57ezZs6V6Lc8N8o0bN9aePXtUXFzsdLWq5G0xq57x1bhxYx04cKDUdquPc6HNmzfr+PHj+uijj9S5c2dz+6FDh8qsP3LkiPLy8pyuVv3nP/+R9McnNCWpadOm+vbbb3XfffdV6NOJ9erV0+DBgzV48GCdPn1anTt31tSpUwlVuC7x9h9QDZRclZo8ebLS0tIueZVK+iMIXXhFpW3btpJkvgXYuHFjubq6auvWrU51CxYscFovuWJz4XwV/UqVzz//XJMmTdLEiRPVp0+fMmtcXV1LHe/NN98sdRWtJBBcGLbK0rNnT2VmZmr58uXmtnPnzunNN9+Ul5eXunTpUr4T+ZPj7NixQykpKea2vLw8LV68WMHBwQoNDbXkOBcq6/epoKCg1O9niXPnzumtt95yqn3rrbfk5+ensLAwSX9cofzvf/+rt99+u9T+Z86cUV5e3kX7ufBxG15eXmrWrFmF34IGrjauVAHVQEhIiO666y6tWbNGki4rVC1ZskQLFizQww8/rKZNm+rUqVN6++23Zbfb1bNnT0mSt7e3Hn30Ub355puy2Wxq2rSpkpKSSt0nY7fb1blzZ82cOVOFhYW66aab9Nlnn130Csil9OvXT35+fmrevLn+9a9/OY3df//98vf3V69evbR06VJ5e3srNDRUKSkp+vzzz81HLpRo27atXF1d9eqrryo3N1fu7u6699571aBBg1LHHTZsmN566y0NGjRIqampCg4O1ocffqivvvpKc+bMUZ06dSp0PhcaP3683n//fT3wwAMaOXKk6tWrpyVLlujQoUP63//931L3dJXHrl279NJLL5Xa3rVrV911112qW7euBg4cqJEjR8pms2np0qUXfbsyMDBQr776qjIyMtSiRQstX75caWlpWrx4sfnIiAEDBmjFihV66qmntGnTJnXq1ElFRUVKT0/XihUrtH79erVr167M+UNDQ9W1a1eFhYWpXr162rVrlz788EO+agfXr0r85CGAa2j+/PmGJKNDhw5ljl/4KIPdu3cb/fr1M26++WbD3d3daNCggdGrVy9j165dTvsdO3bMiImJMWrVqmXUrVvXePLJJ419+/aVeqTCr7/+ajz88MOGj4+P4e3tbTz66KPGkSNHDEnGlClTLtqHYZR+tIGkiy4lj0Y4efKkMXjwYKN+/fqGl5eXERUVZaSnp5f62L5hGMbbb79tNGnSxHB1dXWao6xHOWRlZZnzurm5Ga1bt3Y6T8P4v0cqvPbaa6Ve5wvP92IOHjxoPPLII4aPj4/h4eFhdOjQwUhKSipzvvI8UuFiy4svvmgYhmF89dVXRseOHQ1PT08jMDDQGDt2rLF+/fpSj53o0qWLceuttxq7du0yIiIiDA8PD6Nx48bGvHnzSh23oKDAePXVV41bb73VcHd3N+rWrWuEhYUZ06ZNM3Jzc826C39vXnrpJaNDhw6Gj4+P4enpabRs2dJ4+eWXzcc1ANcbm2Fcp3dMAgAAVCHcUwUAAGABQhUAAIAFCFUAAAAWIFQBAABYgFAFAABgAUIVAACABXj45zVUXFysI0eOqE6dOhX6ugYAAHDtGYahU6dOKTAw8E8fvkuouoaOHDnyp18eCgAArl+//PKLGjVqdNFxQtU1VPIVFr/88ovsdnsldwMAAC6Hw+FQUFDQJb+KilB1DZW85We32wlVAABUMZe6dYcb1QEAACxAqAIAALAAoQoAAMAChCoAAAALEKoAAAAsQKgCAACwAKEKAADAAoQqAAAACxCqAAAALECoAgAAsAChCgAAwAKEKgAAAAsQqgAAACxAqAIAALAAoQoAAMACNSq7AVQPwePXVnYLuIYyXomu7BYA4JrjShUAAIAFCFUAAAAWIFQBAABYgFAFAABgAUIVAACABQhVAAAAFiBUAQAAWIBQBQAAYAFCFQAAgAUIVQAAABYgVAEAAFiAUAUAAGABQhUAAIAFCFUAAAAWIFQBAABYgFAFAABgAUIVAACABQhVAAAAFiBUAQAAWIBQBQAAYAFCFQAAgAUIVQAAABYgVAEAAFiAUAUAAGABQhUAAIAFCFUAAAAWIFQBAABYgFAFAABgAUIVAACABQhVAAAAFiBUAQAAWIBQBQAAYAFCFQAAgAUIVQAAABYgVAEAAFiAUAUAAGABQhUAAIAFKjVUzZgxQ+3bt1edOnXUoEED9enTRwcOHHCq6dq1q2w2m9Py1FNPOdUcPnxY0dHRqlWrlho0aKDnnntO586dc6rZvHmz7rzzTrm7u6tZs2ZKTEws1c/8+fMVHBwsDw8PhYeHa8eOHU7jZ8+eVVxcnHx9feXl5aWYmBhlZWVZ82IAAIAqrVJD1ZYtWxQXF6ft27drw4YNKiwsVPfu3ZWXl+dU98QTT+jo0aPmMnPmTHOsqKhI0dHRKigo0LZt27RkyRIlJiZq8uTJZs2hQ4cUHR2tbt26KS0tTaNGjdLQoUO1fv16s2b58uVKSEjQlClTtHv3brVp00ZRUVHKzs42a0aPHq2PP/5YK1eu1JYtW3TkyBH17dv3Kr5CAACgqrAZhmFUdhMljh07pgYNGmjLli3q3LmzpD+uVLVt21Zz5swpc59PP/1UvXr10pEjR+Tv7y9JWrRokcaNG6djx47Jzc1N48aN09q1a7Vv3z5zv9jYWOXk5GjdunWSpPDwcLVv317z5s2TJBUXFysoKEgjRozQ+PHjlZubKz8/Py1btkyPPPKIJCk9PV2tWrVSSkqKOnbseMnzczgc8vb2Vm5urux2e4Vfp6ooePzaym4B11DGK9GV3QIAWOZyf35fV/dU5ebmSpLq1avntP29995T/fr1ddttt2nChAn6/fffzbGUlBS1bt3aDFSSFBUVJYfDof3795s1kZGRTnNGRUUpJSVFklRQUKDU1FSnGhcXF0VGRpo1qampKiwsdKpp2bKlbr75ZrPmQvn5+XI4HE4LAAC4MdWo7AZKFBcXa9SoUerUqZNuu+02c/tf//pXNW7cWIGBgdqzZ4/GjRunAwcO6KOPPpIkZWZmOgUqSeZ6Zmbmn9Y4HA6dOXNGJ0+eVFFRUZk16enp5hxubm7y8fEpVVNynAvNmDFD06ZNK+crAQAAqqLrJlTFxcVp3759+vLLL522Dxs2zPx169at1bBhQ9133306ePCgmjZteq3bLJcJEyYoISHBXHc4HAoKCqrEjgAAwNVyXbz9Fx8fr6SkJG3atEmNGjX609rw8HBJ0o8//ihJCggIKPUJvJL1gICAP62x2+3y9PRU/fr15erqWmbN+XMUFBQoJyfnojUXcnd3l91ud1oAAMCNqVJDlWEYio+P16pVq7Rx40aFhIRccp+0tDRJUsOGDSVJERER2rt3r9On9DZs2CC73a7Q0FCzJjk52WmeDRs2KCIiQpLk5uamsLAwp5ri4mIlJyebNWFhYapZs6ZTzYEDB3T48GGzBgAAVF+V+vZfXFycli1bpjVr1qhOnTrmvUne3t7y9PTUwYMHtWzZMvXs2VO+vr7as2ePRo8erc6dO+v222+XJHXv3l2hoaEaMGCAZs6cqczMTE2aNElxcXFyd3eXJD311FOaN2+exo4dq8cff1wbN27UihUrtHbt/30iLSEhQQMHDlS7du3UoUMHzZkzR3l5eRo8eLDZ05AhQ5SQkKB69erJbrdrxIgRioiIuKxP/gEAgBtbpYaqhQsXSvrjsQnne/fddzVo0CC5ubnp888/NwNOUFCQYmJiNGnSJLPW1dVVSUlJGj58uCIiIlS7dm0NHDhQ06dPN2tCQkK0du1ajR49Wm+88YYaNWqkd955R1FRUWbNY489pmPHjmny5MnKzMxU27ZttW7dOqeb12fPni0XFxfFxMQoPz9fUVFRWrBgwVV6dQAAQFVyXT2n6kbHc6pQXfCcKgA3kir5nCoAAICqilAFAABgAUIVAACABQhVAAAAFiBUAQAAWIBQBQAAYAFCFQAAgAUIVQAAABYgVAEAAFiAUAUAAGABQhUAAIAFCFUAAAAWIFQBAABYgFAFAABgAUIVAACABQhVAAAAFiBUAQAAWIBQBQAAYAFCFQAAgAUIVQAAABYgVAEAAFiAUAUAAGABQhUAAIAFCFUAAAAWIFQBAABYgFAFAABgAUIVAACABQhVAAAAFiBUAQAAWIBQBQAAYAFCFQAAgAUIVQAAABYgVAEAAFiAUAUAAGABQhUAAIAFCFUAAAAWIFQBAABYgFAFAABgAUIVAACABQhVAAAAFiBUAQAAWIBQBQAAYAFCFQAAgAUIVQAAABYgVAEAAFiAUAUAAGABQhUAAIAFCFUAAAAWIFQBAABYgFAFAABgAUIVAACABSo1VM2YMUPt27dXnTp11KBBA/Xp00cHDhxwqjl79qzi4uLk6+srLy8vxcTEKCsry6nm8OHDio6OVq1atdSgQQM999xzOnfunFPN5s2bdeedd8rd3V3NmjVTYmJiqX7mz5+v4OBgeXh4KDw8XDt27Ch3LwAAoHqq1FC1ZcsWxcXFafv27dqwYYMKCwvVvXt35eXlmTWjR4/Wxx9/rJUrV2rLli06cuSI+vbta44XFRUpOjpaBQUF2rZtm5YsWaLExERNnjzZrDl06JCio6PVrVs3paWladSoURo6dKjWr19v1ixfvlwJCQmaMmWKdu/erTZt2igqKkrZ2dmX3QsAAKi+bIZhGJXdRIljx46pQYMG2rJlizp37qzc3Fz5+flp2bJleuSRRyRJ6enpatWqlVJSUtSxY0d9+umn6tWrl44cOSJ/f39J0qJFizRu3DgdO3ZMbm5uGjdunNauXat9+/aZx4qNjVVOTo7WrVsnSQoPD1f79u01b948SVJxcbGCgoI0YsQIjR8//rJ6uRSHwyFvb2/l5ubKbrdb+tpd74LHr63sFnANZbwSXdktAIBlLvfn93V1T1Vubq4kqV69epKk1NRUFRYWKjIy0qxp2bKlbr75ZqWkpEiSUlJS1Lp1azNQSVJUVJQcDof2799v1pw/R0lNyRwFBQVKTU11qnFxcVFkZKRZczm9XCg/P18Oh8NpAQAAN6brJlQVFxdr1KhR6tSpk2677TZJUmZmptzc3OTj4+NU6+/vr8zMTLPm/EBVMl4y9mc1DodDZ86c0W+//aaioqIya86f41K9XGjGjBny9vY2l6CgoMt8NQAAQFVz3YSquLg47du3Tx988EFlt2KZCRMmKDc311x++eWXym4JAABcJTUquwFJio+PV1JSkrZu3apGjRqZ2wMCAlRQUKCcnBynK0RZWVkKCAgway78lF7JJ/LOr7nwU3pZWVmy2+3y9PSUq6urXF1dy6w5f45L9XIhd3d3ubu7l+OVAAAAVVWlXqkyDEPx8fFatWqVNm7cqJCQEKfxsLAw1axZU8nJyea2AwcO6PDhw4qIiJAkRUREaO/evU6f0tuwYYPsdrtCQ0PNmvPnKKkpmcPNzU1hYWFONcXFxUpOTjZrLqcXAABQfVXqlaq4uDgtW7ZMa9asUZ06dcx7k7y9veXp6Slvb28NGTJECQkJqlevnux2u0aMGKGIiAjz03bdu3dXaGioBgwYoJkzZyozM1OTJk1SXFyceZXoqaee0rx58zR27Fg9/vjj2rhxo1asWKG1a//vE2kJCQkaOHCg2rVrpw4dOmjOnDnKy8vT4MGDzZ4u1QsAAKi+KjVULVy4UJLUtWtXp+3vvvuuBg0aJEmaPXu2XFxcFBMTo/z8fEVFRWnBggVmraurq5KSkjR8+HBFRESodu3aGjhwoKZPn27WhISEaO3atRo9erTeeOMNNWrUSO+8846ioqLMmscee0zHjh3T5MmTlZmZqbZt22rdunVON69fqhcAAFB9XVfPqbrR8ZwqVBc8pwrAjaRKPqcKAACgqiJUAQAAWIBQBQAAYAFCFQAAgAUIVQAAABYgVAEAAFiAUAUAAGABQhUAAIAFCFUAAAAWIFQBAABYgFAFAABgAUIVAACABQhVAAAAFiBUAQAAWIBQBQAAYAFCFQAAgAUIVQAAABYgVAEAAFiAUAUAAGABQhUAAIAFCFUAAAAWIFQBAABYgFAFAABgAUIVAACABQhVAAAAFiBUAQAAWIBQBQAAYAFCFQAAgAUIVQAAABYgVAEAAFiAUAUAAGABQhUAAIAFCFUAAAAWIFQBAABYgFAFAABgAUIVAACABQhVAAAAFiBUAQAAWKBCoapJkyY6fvx4qe05OTlq0qTJFTcFAABQ1VQoVGVkZKioqKjU9vz8fP33v/+94qYAAACqmhrlKf73v/9t/nr9+vXy9vY214uKipScnKzg4GDLmgMAAKgqyhWq+vTpI0my2WwaOHCg01jNmjUVHBysWbNmWdYcAABAVVGuUFVcXCxJCgkJ0c6dO1W/fv2r0hQAAEBVU65QVeLQoUNW9wEAAFClVShUSVJycrKSk5OVnZ1tXsEq8Y9//OOKGwMAAKhKKhSqpk2bpunTp6tdu3Zq2LChbDab1X0BAABUKRUKVYsWLVJiYqIGDBhgdT8AAABVUoWeU1VQUKC77rrL6l4AAACqrAqFqqFDh2rZsmVW9wIAAFBlVejtv7Nnz2rx4sX6/PPPdfvtt6tmzZpO46+//rolzQEAAFQVFQpVe/bsUdu2bSVJ+/btcxrjpnUAAFAdVejtv02bNl102bhx42XPs3XrVj344IMKDAyUzWbT6tWrncYHDRokm83mtPTo0cOp5sSJE+rfv7/sdrt8fHw0ZMgQnT592qlmz549uueee+Th4aGgoCDNnDmzVC8rV65Uy5Yt5eHhodatW+uTTz5xGjcMQ5MnT1bDhg3l6empyMhI/fDDD5d9rgAA4MZWoVBllby8PLVp00bz58+/aE2PHj109OhRc3n//fedxvv376/9+/drw4YNSkpK0tatWzVs2DBz3OFwqHv37mrcuLFSU1P12muvaerUqVq8eLFZs23bNvXr109DhgzRN998oz59+qhPnz5OV+FmzpypuXPnatGiRfr6669Vu3ZtRUVF6ezZsxa+IgAAoKqyGYZhlHenbt26/enbfOW5WmU2YrNp1apV5vcLSn9cqcrJySl1BavE999/r9DQUO3cuVPt2rWTJK1bt049e/bUr7/+qsDAQC1cuFATJ05UZmam3NzcJEnjx4/X6tWrlZ6eLkl67LHHlJeXp6SkJHPujh07qm3btlq0aJEMw1BgYKCeffZZjRkzRpKUm5srf39/JSYmKjY29rLO0eFwyNvbW7m5ubLb7eV9iaq04PFrK7sFXEMZr0RXdgsAYJnL/fldoStVbdu2VZs2bcwlNDRUBQUF2r17t1q3bl3hpsuyefNmNWjQQLfccouGDx+u48ePm2MpKSny8fExA5UkRUZGysXFRV9//bVZ07lzZzNQSVJUVJQOHDigkydPmjWRkZFOx42KilJKSoqkP76WJzMz06nG29tb4eHhZk1Z8vPz5XA4nBYAAHBjqtCN6rNnzy5z+9SpU0vdz3QlevToob59+yokJEQHDx7U888/rwceeEApKSlydXVVZmamGjRo4LRPjRo1VK9ePWVmZkqSMjMzFRIS4lTj7+9vjtWtW1eZmZnmtvNrzp/j/P3KqinLjBkzNG3atAqcOQAAqGosvafqb3/7m6Xf+xcbG6vevXurdevW6tOnj5KSkrRz505t3rzZsmNcTRMmTFBubq65/PLLL5XdEgAAuEosDVUpKSny8PCwckonTZo0Uf369fXjjz9KkgICApSdne1Uc+7cOZ04cUIBAQFmTVZWllNNyfqlas4fP3+/smrK4u7uLrvd7rQAAIAbU4Xe/uvbt6/TumEYOnr0qHbt2qUXXnjBksbK8uuvv+r48eNq2LChJCkiIkI5OTlKTU1VWFiYpD9uki8uLlZ4eLhZM3HiRBUWFpoPKd2wYYNuueUW1a1b16xJTk7WqFGjzGNt2LBBERERkqSQkBAFBAQoOTnZfD6Xw+HQ119/reHDh1+18wUAAFVHhUKVt7e307qLi4tuueUWTZ8+Xd27d7/seU6fPm1edZL+uCE8LS1N9erVU7169TRt2jTFxMQoICBABw8e1NixY9WsWTNFRUVJklq1aqUePXroiSee0KJFi1RYWKj4+HjFxsYqMDBQkvTXv/5V06ZN05AhQzRu3Djt27dPb7zxhtN9Yc8884y6dOmiWbNmKTo6Wh988IF27dplPnbBZrNp1KhReumll9S8eXOFhITohRdeUGBgoNOnFQEAQPVVoUcqWGXz5s3q1q1bqe0DBw7UwoUL1adPH33zzTfKyclRYGCgunfvrhdffNHphvETJ04oPj5eH3/8sVxcXBQTE6O5c+fKy8vLrNmzZ4/i4uK0c+dO1a9fXyNGjNC4ceOcjrly5UpNmjRJGRkZat68uWbOnKmePXua44ZhaMqUKVq8eLFycnJ09913a8GCBWrRosVlny+PVEB1wSMVANxILvfn9xWFqtTUVH3//feSpFtvvVV33HFHRaeqFghVqC4IVQBuJJf787tCb/9lZ2crNjZWmzdvlo+PjyQpJydH3bp10wcffCA/P78KNQ0AAFBVVejTfyNGjNCpU6e0f/9+nThxQidOnNC+ffvkcDg0cuRIq3sEAAC47lXoStW6dev0+eefq1WrVua20NBQzZ8/v1w3qgMAANwoKnSlqri42Hw8wflq1qyp4uLiK24KAACgqqlQqLr33nv1zDPP6MiRI+a2//73vxo9erTuu+8+y5oDAACoKioUqubNmyeHw6Hg4GA1bdpUTZs2VUhIiBwOh958802rewQAALjuVeieqqCgIO3evVuff/650tPTJf3xIM7IyEhLmwMAAKgqynWlauPGjQoNDZXD4ZDNZtP999+vESNGaMSIEWrfvr1uvfVWffHFF1erVwAAgOtWuULVnDlz9MQTT5T54Ctvb289+eSTev311y1rDgAAoKooV6j69ttv1aNHj4uOd+/eXampqVfcFAAAQFVTrlCVlZVV5qMUStSoUUPHjh274qYAAACqmnKFqptuukn79u276PiePXvUsGHDK24KAACgqilXqOrZs6deeOEFnT17ttTYmTNnNGXKFPXq1cuy5gAAAKqKcj1SYdKkSfroo4/UokULxcfH65ZbbpEkpaena/78+SoqKtLEiROvSqMAAADXs3KFKn9/f23btk3Dhw/XhAkTZBiGJMlmsykqKkrz58+Xv7//VWkUAADgelbuh382btxYn3zyiU6ePKkff/xRhmGoefPmqlu37tXoDwAAoEqo0BPVJalu3bpq3769lb0AAABUWRX67j8AAAA4I1QBAABYgFAFAABgAUIVAACABQhVAAAAFiBUAQAAWIBQBQAAYAFCFQAAgAUIVQAAABYgVAEAAFiAUAUAAGABQhUAAIAFCFUAAAAWIFQBAABYgFAFAABgAUIVAACABQhVAAAAFiBUAQAAWIBQBQAAYAFCFQAAgAUIVQAAABYgVAEAAFiAUAUAAGABQhUAAIAFCFUAAAAWIFQBAABYgFAFAABgAUIVAACABQhVAAAAFiBUAQAAWIBQBQAAYAFCFQAAgAUIVQAAABYgVAEAAFigUkPV1q1b9eCDDyowMFA2m02rV692GjcMQ5MnT1bDhg3l6empyMhI/fDDD041J06cUP/+/WW32+Xj46MhQ4bo9OnTTjV79uzRPffcIw8PDwUFBWnmzJmlelm5cqVatmwpDw8PtW7dWp988km5ewEAANVXpYaqvLw8tWnTRvPnzy9zfObMmZo7d64WLVqkr7/+WrVr11ZUVJTOnj1r1vTv31/79+/Xhg0blJSUpK1bt2rYsGHmuMPhUPfu3dW4cWOlpqbqtdde09SpU7V48WKzZtu2berXr5+GDBmib775Rn369FGfPn20b9++cvUCAACqL5thGEZlNyFJNptNq1atUp8+fST9cWUoMDBQzz77rMaMGSNJys3Nlb+/vxITExUbG6vvv/9eoaGh2rlzp9q1aydJWrdunXr27Klff/1VgYGBWrhwoSZOnKjMzEy5ublJksaPH6/Vq1crPT1dkvTYY48pLy9PSUlJZj8dO3ZU27ZttWjRosvq5XI4HA55e3srNzdXdrvdktetqggev7ayW8A1lPFKdGW3AACWudyf39ftPVWHDh1SZmamIiMjzW3e3t4KDw9XSkqKJCklJUU+Pj5moJKkyMhIubi46OuvvzZrOnfubAYqSYqKitKBAwd08uRJs+b845TUlBzncnopS35+vhwOh9MCAABuTNdtqMrMzJQk+fv7O2339/c3xzIzM9WgQQOn8Ro1aqhevXpONWXNcf4xLlZz/vileinLjBkz5O3tbS5BQUGXOGsAAFBVXbeh6kYwYcIE5ebmmssvv/xS2S0BAICr5LoNVQEBAZKkrKwsp+1ZWVnmWEBAgLKzs53Gz507pxMnTjjVlDXH+ce4WM3545fqpSzu7u6y2+1OCwAAuDFdt6EqJCREAQEBSk5ONrc5HA59/fXXioiIkCRFREQoJydHqampZs3GjRtVXFys8PBws2br1q0qLCw0azZs2KBbbrlFdevWNWvOP05JTclxLqcXAABQvVVqqDp9+rTS0tKUlpYm6Y8bwtPS0nT48GHZbDaNGjVKL730kv79739r7969+vvf/67AwEDzE4KtWrVSjx499MQTT2jHjh366quvFB8fr9jYWAUGBkqS/vrXv8rNzU1DhgzR/v37tXz5cr3xxhtKSEgw+3jmmWe0bt06zZo1S+np6Zo6dap27dql+Ph4SbqsXgAAQPVWozIPvmvXLnXr1s1cLwk6AwcOVGJiosaOHau8vDwNGzZMOTk5uvvuu7Vu3Tp5eHiY+7z33nuKj4/XfffdJxcXF8XExGju3LnmuLe3tz777DPFxcUpLCxM9evX1+TJk52eZXXXXXdp2bJlmjRpkp5//nk1b95cq1ev1m233WbWXE4vAACg+rpunlNVHfCcKlQXPKcKwI2kyj+nCgAAoCohVAEAAFiAUAUAAGABQhUAAIAFCFUAAAAWIFQBAABYgFAFAABgAUIVAACABQhVAAAAFiBUAQAAWIBQBQAAYAFCFQAAgAUIVQAAABYgVAEAAFiAUAUAAGABQhUAAIAFCFUAAAAWIFQBAABYgFAFAABgAUIVAACABQhVAAAAFiBUAQAAWIBQBQAAYAFCFQAAgAUIVQAAABYgVAEAAFiAUAUAAGABQhUAAIAFCFUAAAAWIFQBAABYgFAFAABgAUIVAACABQhVAAAAFiBUAQAAWIBQBQAAYAFCFQAAgAUIVQAAABYgVAEAAFiAUAUAAGABQhUAAIAFCFUAAAAWIFQBAABYgFAFAABgAUIVAACABQhVAAAAFiBUAQAAWIBQBQAAYAFCFQAAgAUIVQAAABYgVAEAAFiAUAUAAGCB6zpUTZ06VTabzWlp2bKlOX727FnFxcXJ19dXXl5eiomJUVZWltMchw8fVnR0tGrVqqUGDRroueee07lz55xqNm/erDvvvFPu7u5q1qyZEhMTS/Uyf/58BQcHy8PDQ+Hh4dqxY8dVOWcAAFA1XdehSpJuvfVWHT161Fy+/PJLc2z06NH6+OOPtXLlSm3ZskVHjhxR3759zfGioiJFR0eroKBA27Zt05IlS5SYmKjJkyebNYcOHVJ0dLS6deumtLQ0jRo1SkOHDtX69evNmuXLlyshIUFTpkzR7t271aZNG0VFRSk7O/vavAgAAOC6ZzMMw6jsJi5m6tSpWr16tdLS0kqN5ebmys/PT8uWLdMjjzwiSUpPT1erVq2UkpKijh076tNPP1WvXr105MgR+fv7S5IWLVqkcePG6dixY3Jzc9O4ceO0du1a7du3z5w7NjZWOTk5WrdunSQpPDxc7du317x58yRJxcXFCgoK0ogRIzR+/PjLPh+HwyFvb2/l5ubKbrdX9GWpkoLHr63sFnANZbwSXdktAIBlLvfn93V/peqHH35QYGCgmjRpov79++vw4cOSpNTUVBUWFioyMtKsbdmypW6++WalpKRIklJSUtS6dWszUElSVFSUHA6H9u/fb9acP0dJTckcBQUFSk1NdapxcXFRZGSkWXMx+fn5cjgcTgsAALgxXdehKjw8XImJiVq3bp0WLlyoQ4cO6Z577tGpU6eUmZkpNzc3+fj4OO3j7++vzMxMSVJmZqZToCoZLxn7sxqHw6EzZ87ot99+U1FRUZk1JXNczIwZM+Tt7W0uQUFB5X4NAABA1VCjshv4Mw888ID569tvv13h4eFq3LixVqxYIU9Pz0rs7PJMmDBBCQkJ5rrD4SBYAQBwg7qur1RdyMfHRy1atNCPP/6ogIAAFRQUKCcnx6kmKytLAQEBkqSAgIBSnwYsWb9Ujd1ul6enp+rXry9XV9cya0rmuBh3d3fZ7XanBQAA3JiqVKg6ffq0Dh48qIYNGyosLEw1a9ZUcnKyOX7gwAEdPnxYERERkqSIiAjt3bvX6VN6GzZskN1uV2hoqFlz/hwlNSVzuLm5KSwszKmmuLhYycnJZg0AAMB1HarGjBmjLVu2KCMjQ9u2bdPDDz8sV1dX9evXT97e3hoyZIgSEhK0adMmpaamavDgwYqIiFDHjh0lSd27d1doaKgGDBigb7/9VuvXr9ekSZMUFxcnd3d3SdJTTz2ln376SWPHjlV6eroWLFigFStWaPTo0WYfCQkJevvtt7VkyRJ9//33Gj58uPLy8jR48OBKeV0AAMD157q+p+rXX39Vv379dPz4cfn5+enuu+/W9u3b5efnJ0maPXu2XFxcFBMTo/z8fEVFRWnBggXm/q6urkpKStLw4cMVERGh2rVra+DAgZo+fbpZExISorVr12r06NF644031KhRI73zzjuKiooyax577DEdO3ZMkydPVmZmptq2bat169aVunkdAABUX9f1c6puNDynCtUFz6kCcCO5YZ5TBQAAUBUQqgAAACxAqAIAALAAoQoAAMAChCoAAAALEKoAAAAsQKgCAACwAKEKAADAAoQqAAAACxCqAAAALECoAgAAsAChCgAAwAKEKgAAAAsQqgAAACxAqAIAALAAoQoAAMAChCoAAAALEKoAAAAsQKgCAACwAKEKAADAAoQqAAAACxCqAAAALECoAgAAsAChCgAAwAKEKgAAAAsQqgAAACxAqAIAALAAoQoAAMAChCoAAAALEKoAAAAsQKgCAACwAKEKAADAAoQqAAAACxCqAAAALECoAgAAsAChCgAAwAKEKgAAAAsQqgAAACxAqAIAALAAoQoAAMAChCoAAAALEKoAAAAsQKgCAACwAKEKAADAAoQqAAAACxCqAAAALECoAgAAsAChCgAAwAKEKgAAAAsQqgAAACxAqCqn+fPnKzg4WB4eHgoPD9eOHTsquyUAAHAdIFSVw/Lly5WQkKApU6Zo9+7datOmjaKiopSdnV3ZrQEAgEpGqCqH119/XU888YQGDx6s0NBQLVq0SLVq1dI//vGPym4NAABUMkLVZSooKFBqaqoiIyPNbS4uLoqMjFRKSkoldgYAAK4HNSq7garit99+U1FRkfz9/Z22+/v7Kz09vcx98vPzlZ+fb67n5uZKkhwOx9Vr9DpVnP97ZbeAa6g6/hmvzm6bsr6yW8A1tG9aVGW3cM2V/JtmGMaf1hGqrqIZM2Zo2rRppbYHBQVVQjfAteM9p7I7AHC1VOe/36dOnZK3t/dFxwlVl6l+/fpydXVVVlaW0/asrCwFBASUuc+ECROUkJBgrhcXF+vEiRPy9fWVzWa7qv2i8jkcDgUFBemXX36R3W6v7HYAWIi/39WLYRg6deqUAgMD/7SOUHWZ3NzcFBYWpuTkZPXp00fSHyEpOTlZ8fHxZe7j7u4ud3d3p20+Pj5XuVNcb+x2O//oAjco/n5XH392haoEoaocEhISNHDgQLVr104dOnTQnDlzlJeXp8GDB1d2awAAoJIRqsrhscce07FjxzR58mRlZmaqbdu2WrduXamb1wEAQPVDqCqn+Pj4i77dB5zP3d1dU6ZMKfUWMICqj7/fKIvNuNTnAwEAAHBJPPwTAADAAoQqAAAACxCqAAAALECoAiqZzWbT6tWrK7sNANfYoEGDzOce4sZAqEK1lJmZqWeeeUbNmjWTh4eH/P391alTJy1cuFC//35tv6fw6NGjeuCBB67pMYHqbNCgQbLZbKWWH3/8sbJbQxXHIxVQ7fz000/q1KmTfHx89D//8z9q3bq13N3dtXfvXi1evFg33XSTevfufc36udjXHAG4enr06KF3333XaZufn5/TekFBgdzc3K5lW6jiuFKFaufpp59WjRo1tGvXLv3lL39Rq1at1KRJEz300ENau3atHnzwQUlSTk6Ohg4dKj8/P9ntdt1777369ttvzXmmTp2qtm3baunSpQoODpa3t7diY2N16tQpsyY4OFhz5sxxOn7btm01depUc/38t/8yMjJks9n00UcfqVu3bqpVq5batGmjlJQUpzm+/PJL3XPPPfL09FRQUJBGjhypvLw8a18o4Abm7u6ugIAAp+W+++5TfHy8Ro0apfr16ysqKkqS9Prrr6t169aqXbu2goKC9PTTT+v06dPmXCX/Fpxvzpw5Cg4ONteLioqUkJAgHx8f+fr6auzYseKJRjceQhWqlePHj+uzzz5TXFycateuXWZNyZddP/roo8rOztann36q1NRU3Xnnnbrvvvt04sQJs/bgwYNavXq1kpKSlJSUpC1btuiVV1654j4nTpyoMWPGKC0tTS1atFC/fv107tw585g9evRQTEyM9uzZo+XLl+vLL7/kobSABZYsWSI3Nzd99dVXWrRokSTJxcVFc+fO1f79+7VkyRJt3LhRY8eOLde8s2bNUmJiov7xj3/oyy+/1IkTJ7Rq1aqrcQqoTAZQjWzfvt2QZHz00UdO2319fY3atWsbtWvXNsaOHWt88cUXht1uN86ePetU17RpU+Ott94yDMMwpkyZYtSqVctwOBzm+HPPPWeEh4eb640bNzZmz57tNEebNm2MKVOmmOuSjFWrVhmGYRiHDh0yJBnvvPOOOb5//35DkvH9998bhmEYQ4YMMYYNG+Y05xdffGG4uLgYZ86cKd8LAlRDAwcONFxdXc2/87Vr1zYeeeQRo0uXLsYdd9xxyf1Xrlxp+Pr6mutTpkwx2rRp41Qze/Zso3HjxuZ6w4YNjZkzZ5rrhYWFRqNGjYyHHnroSk8H1xHuqQIk7dixQ8XFxerfv7/y8/P17bff6vTp0/L19XWqO3PmjA4ePGiuBwcHq06dOuZ6w4YNlZ2dfcX93H777U5zSlJ2drZatmypb7/9Vnv27NF7771n1hiGoeLiYh06dEitWrW64uMDN7pu3bpp4cKF5nrt2rXVr18/hYWFlar9/PPPNWPGDKWnp8vhcOjcuXM6e/asfv/9d9WqVeuSx8rNzdXRo0cVHh5ubqtRo4batWvHW4A3GEIVqpVmzZrJZrPpwIEDTtubNGkiSfL09JQknT59Wg0bNtTmzZtLzeHj42P+umbNmk5jNptNxcXF5rqLi0upfzQLCwsv2ef585a8HVky7+nTp/Xkk09q5MiRpfa7+eabLzk3gD9CVLNmzcrcfr6MjAz16tVLw4cP18svv6x69erpyy+/1JAhQ1RQUKBatWpV+O85bjyEKlQrvr6+uv/++zVv3jyNGDHiovdV3XnnncrMzFSNGjWcbjYtLz8/Px09etRcdzgcOnToUIXnK+ntu+++K/MHAgBrpaamqri4WLNmzZKLyx+3Ia9YscKpxs/PT5mZmTIMw/yfoLS0NHPc29tbDRs21Ndff63OnTtLks6dO2feq4kbBzeqo9pZsGCBzp07p3bt2mn58uX6/vvvdeDAAf3rX/9Senq6XF1dFRkZqYiICPXp00efffaZMjIytG3bNk2cOFG7du267GPde++9Wrp0qb744gvt3btXAwcOlKur6xX1P27cOG3btk3x8fFKS0vTDz/8oDVr1nCjOnAVNGvWTIWFhXrzzTf1008/aenSpeYN7CW6du2qY8eOaebMmTp48KDmz5+vTz/91KnmmWee0SuvvKLVq1crPT1dTz/9tHJycq7hmeBaIFSh2mnatKm++eYbRUZGasKECWrTpo3atWunN998U2PGjNGLL74om82mTz75RJ07d9bgwYPVokULxcbG6ueff5a/v/9lH2vChAnq0qWLevXqpejoaPXp00dNmza9ov5vv/12bdmyRf/5z390zz336I477tDkyZMVGBh4RfMCKK1NmzZ6/fXX9eqrr+q2227Te++9pxkzZjjVtGrVSgsWLND8+fPVpk0b7dixQ2PGjHGqefbZZzVgwAANHDhQERERqlOnjh5++OFreSq4BmwGd8kBAABcMa5UAQAAWIBQBQAAYAFCFQAAgAUIVQAAABYgVAEAAFiAUAUAAGABQhUAAIAFCFUAcJlsNptWr15d2W0AuE4RqgDg/5eZmakRI0aoSZMmcnd3V1BQkB588EElJydXdmsAqgC+UBkAJGVkZKhTp07y8fHRa6+9ptatW6uwsFDr169XXFyc0tPTK7tFANc5rlQBgKSnn35aNptNO3bsUExMjFq0aKFbb71VCQkJ2r59e5n7jBs3Ti1atFCtWrXUpEkTvfDCCyosLDTHv/32W3Xr1k116tSR3W5XWFiY+YXcP//8sx588EHVrVtXtWvX1q233qpPPvnkmpwrgKuDK1UAqr0TJ05o3bp1evnll1W7du1S4z4+PmXuV6dOHSUmJiowMFB79+7VE088oTp16mjs2LGSpP79++uOO+7QwoUL5erqqrS0NNWsWVOSFBcXp4KCAm3dulW1a9fWd999Jy8vr6t2jgCuPkIVgGrvxx9/lGEYatmyZbn2mzRpkvnr4OBgjRkzRh988IEZqg4fPqznnnvOnLd58+Zm/eHDhxUTE6PWrVtLkpo0aXKlpwGgkvH2H4BqzzCMCu23fPlyderUSQEBAfLy8tKkSZN0+PBhczwhIUFDhw5VZGSkXnnlFR08eNAcGzlypF566SV16tRJU6ZM0Z49e674PABULkIVgGqvefPmstls5boZPSUlRf3791fPnj2VlJSkb775RhMnTlRBQYFZM3XqVO3fv1/R0dHauHGjQkNDtWrVKknS0KFD9dNPP2nAgAHau3ev2rVrpzfffNPycwNw7diMiv4vGgDcQB544AHt3btXBw4cKHVfVU5Ojnx8fGSz2bRq1Sr16dNHs2bN0oIFC5yuPg0dOlQffvihcnJyyjxGv379lJeXp3//+9+lxiZMmKC1a9dyxQqowrhSBQCS5s+fr6KiInXo0EH/+7//qx9++EHff/+95s6dq4iIiFL1zZs31+HDh/XBBx/o4MGDmjt3rnkVSpLOnDmj+Ph4bd68WT///LO++uor7dy5U61atZIkjRo1SuvXr9ehQ4e0e/dubdq0yRwDUDVxozoA6I8bxXfv3q2XX35Zzz77rI4ePSo/Pz+FhYVp4cKFpep79+6t0aNHKz4+Xvn5+YqOjtYLL7ygqVOnSpJcXV11/Phx/f3vf1dWVpbq16+vvn37atq0aZKkoqIixcXF6ddff5XdblePHj00e/bsa3nKACzG238AAAAW4O0/AAAACxCqAAAALECoAgAAsAChCgAAwAKEKgAAAAsQqgAAACxAqAIAALAAoQoAAMAChCoAAAALEKoAAAAsQKgCAACwAKEKAADAAv8fnpq1A0xxQBgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = [\"Genuine\", \"Fraud\"]\n",
    "count_classes = df.value_counts(df['Class'], sort= True)\n",
    "count_classes.plot(kind = \"bar\", rot = 0)\n",
    "plt.title(\"Visualization of Labels\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(range(2), labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply Standard Scaler to scale the amount class\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df['NormalizedAmount'] = scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "df.drop([\"Amount\", \"Time\"], inplace= True, axis= 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>NormalizedAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Class  NormalizedAmount  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053      0          0.244964  \n",
       "1  0.167170  0.125895 -0.008983  0.014724      0         -0.342475  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752      0          1.160686  \n",
       "3  0.647376 -0.221929  0.062723  0.061458      0          0.140534  \n",
       "4 -0.206010  0.502292  0.219422  0.215153      0         -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"Class\"], axis= 1)\n",
    "y = df[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdc=RandomForestClassifier(n_estimators=100)\n",
    "dtc=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdc.fit(X_train,y_train)\n",
    "y_pred=rdc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc.fit(X_train,y_train)\n",
    "y_pred1=dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score,recall_score,f1_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For RandomForest classification\n",
      "Accuracy score:  0.9996488887328394\n",
      "Precision score:  0.9416666666666667\n",
      "Recall score:  0.8308823529411765\n",
      "F1 score:  0.8828125\n",
      "Confusion matrix: \n",
      " [[85300     7]\n",
      " [   23   113]]\n",
      "Classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.94      0.83      0.88       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.97      0.92      0.94     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('For RandomForest classification')\n",
    "print('Accuracy score: ',accuracy_score(y_test,y_pred))\n",
    "print('Precision score: ',precision_score(y_test,y_pred))\n",
    "print('Recall score: ',recall_score(y_test,y_pred))\n",
    "print('F1 score: ',f1_score(y_test,y_pred))\n",
    "print('Confusion matrix: \\n',confusion_matrix(y_test,y_pred))\n",
    "print('Classification_report: \\n',classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Decision_tree\n",
      "Accuracy score:  0.9991573329588147\n",
      "Precision score:  0.7133333333333334\n",
      "Recall score:  0.7867647058823529\n",
      "F1 score:  0.7482517482517482\n",
      "Confusion matrix: \n",
      " [[85264    43]\n",
      " [   29   107]]\n",
      "Classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.71      0.79      0.75       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.86      0.89      0.87     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('For Decision_tree')\n",
    "print('Accuracy score: ',accuracy_score(y_test,y_pred1))\n",
    "print('Precision score: ',precision_score(y_test,y_pred1))\n",
    "print('Recall score: ',recall_score(y_test,y_pred1))\n",
    "print('F1 score: ',f1_score(y_test,y_pred1))\n",
    "print('Confusion matrix: \\n',confusion_matrix(y_test,y_pred1))\n",
    "print('Classification_report: \\n',classification_report(y_test,y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here there is imbalanced dataset problem \n",
    "### Let us solve this problem by oversampling (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled shape of X:  (568630, 29)\n",
      "Resampled shape of y:  (568630,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "X_resampled, y_resampled = SMOTE().fit_resample(X, y)\n",
    "print(\"Resampled shape of X: \", X_resampled.shape)\n",
    "print(\"Resampled shape of y: \", y_resampled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>NormalizedAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568625</th>\n",
       "      <td>-2.046770</td>\n",
       "      <td>3.564217</td>\n",
       "      <td>-4.290093</td>\n",
       "      <td>2.697131</td>\n",
       "      <td>-2.076105</td>\n",
       "      <td>-2.465441</td>\n",
       "      <td>-3.978968</td>\n",
       "      <td>1.611070</td>\n",
       "      <td>-1.137010</td>\n",
       "      <td>-6.552113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457245</td>\n",
       "      <td>0.584249</td>\n",
       "      <td>-0.527096</td>\n",
       "      <td>0.014283</td>\n",
       "      <td>0.195908</td>\n",
       "      <td>0.076764</td>\n",
       "      <td>0.307608</td>\n",
       "      <td>0.545708</td>\n",
       "      <td>0.281371</td>\n",
       "      <td>-0.349231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568626</th>\n",
       "      <td>1.164409</td>\n",
       "      <td>2.449393</td>\n",
       "      <td>-4.847102</td>\n",
       "      <td>5.383107</td>\n",
       "      <td>0.885697</td>\n",
       "      <td>-1.230132</td>\n",
       "      <td>-1.306802</td>\n",
       "      <td>0.378197</td>\n",
       "      <td>-2.542290</td>\n",
       "      <td>-3.024544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219858</td>\n",
       "      <td>0.143328</td>\n",
       "      <td>-0.647769</td>\n",
       "      <td>-0.073730</td>\n",
       "      <td>-0.893156</td>\n",
       "      <td>0.320923</td>\n",
       "      <td>0.074135</td>\n",
       "      <td>0.483937</td>\n",
       "      <td>0.267174</td>\n",
       "      <td>-0.335280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568627</th>\n",
       "      <td>-1.022006</td>\n",
       "      <td>1.095719</td>\n",
       "      <td>-0.324821</td>\n",
       "      <td>1.376180</td>\n",
       "      <td>1.744578</td>\n",
       "      <td>-2.082929</td>\n",
       "      <td>0.502570</td>\n",
       "      <td>-0.090173</td>\n",
       "      <td>-0.136931</td>\n",
       "      <td>-2.497117</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.173992</td>\n",
       "      <td>-0.338038</td>\n",
       "      <td>-0.844721</td>\n",
       "      <td>-0.343783</td>\n",
       "      <td>0.226885</td>\n",
       "      <td>0.468076</td>\n",
       "      <td>-0.498642</td>\n",
       "      <td>0.011416</td>\n",
       "      <td>0.134258</td>\n",
       "      <td>-0.349231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568628</th>\n",
       "      <td>-3.523047</td>\n",
       "      <td>2.069972</td>\n",
       "      <td>-2.574803</td>\n",
       "      <td>-0.258915</td>\n",
       "      <td>-1.815361</td>\n",
       "      <td>-1.626761</td>\n",
       "      <td>-1.376705</td>\n",
       "      <td>0.012335</td>\n",
       "      <td>0.245840</td>\n",
       "      <td>-3.514126</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.629818</td>\n",
       "      <td>0.437988</td>\n",
       "      <td>-0.220391</td>\n",
       "      <td>-0.576471</td>\n",
       "      <td>0.258923</td>\n",
       "      <td>-0.502408</td>\n",
       "      <td>-1.024764</td>\n",
       "      <td>-0.808659</td>\n",
       "      <td>0.126030</td>\n",
       "      <td>0.271290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568629</th>\n",
       "      <td>-2.464969</td>\n",
       "      <td>-2.418144</td>\n",
       "      <td>1.131053</td>\n",
       "      <td>2.075085</td>\n",
       "      <td>0.969892</td>\n",
       "      <td>-0.565596</td>\n",
       "      <td>0.560537</td>\n",
       "      <td>-0.084028</td>\n",
       "      <td>-0.309591</td>\n",
       "      <td>-0.658776</td>\n",
       "      <td>...</td>\n",
       "      <td>1.803702</td>\n",
       "      <td>0.584364</td>\n",
       "      <td>0.513610</td>\n",
       "      <td>1.129895</td>\n",
       "      <td>-0.410533</td>\n",
       "      <td>0.195460</td>\n",
       "      <td>-0.118409</td>\n",
       "      <td>-0.206857</td>\n",
       "      <td>0.012073</td>\n",
       "      <td>1.531994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568630 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0      -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1       1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2      -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3      -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4      -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "568625 -2.046770  3.564217 -4.290093  2.697131 -2.076105 -2.465441 -3.978968   \n",
       "568626  1.164409  2.449393 -4.847102  5.383107  0.885697 -1.230132 -1.306802   \n",
       "568627 -1.022006  1.095719 -0.324821  1.376180  1.744578 -2.082929  0.502570   \n",
       "568628 -3.523047  2.069972 -2.574803 -0.258915 -1.815361 -1.626761 -1.376705   \n",
       "568629 -2.464969 -2.418144  1.131053  2.075085  0.969892 -0.565596  0.560537   \n",
       "\n",
       "              V8        V9       V10  ...       V20       V21       V22  \\\n",
       "0       0.098698  0.363787  0.090794  ...  0.251412 -0.018307  0.277838   \n",
       "1       0.085102 -0.255425 -0.166974  ... -0.069083 -0.225775 -0.638672   \n",
       "2       0.247676 -1.514654  0.207643  ...  0.524980  0.247998  0.771679   \n",
       "3       0.377436 -1.387024 -0.054952  ... -0.208038 -0.108300  0.005274   \n",
       "4      -0.270533  0.817739  0.753074  ...  0.408542 -0.009431  0.798278   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "568625  1.611070 -1.137010 -6.552113  ...  0.457245  0.584249 -0.527096   \n",
       "568626  0.378197 -2.542290 -3.024544  ...  0.219858  0.143328 -0.647769   \n",
       "568627 -0.090173 -0.136931 -2.497117  ... -0.173992 -0.338038 -0.844721   \n",
       "568628  0.012335  0.245840 -3.514126  ... -0.629818  0.437988 -0.220391   \n",
       "568629 -0.084028 -0.309591 -0.658776  ...  1.803702  0.584364  0.513610   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "...          ...       ...       ...       ...       ...       ...   \n",
       "568625  0.014283  0.195908  0.076764  0.307608  0.545708  0.281371   \n",
       "568626 -0.073730 -0.893156  0.320923  0.074135  0.483937  0.267174   \n",
       "568627 -0.343783  0.226885  0.468076 -0.498642  0.011416  0.134258   \n",
       "568628 -0.576471  0.258923 -0.502408 -1.024764 -0.808659  0.126030   \n",
       "568629  1.129895 -0.410533  0.195460 -0.118409 -0.206857  0.012073   \n",
       "\n",
       "        NormalizedAmount  \n",
       "0               0.244964  \n",
       "1              -0.342475  \n",
       "2               1.160686  \n",
       "3               0.140534  \n",
       "4              -0.073403  \n",
       "...                  ...  \n",
       "568625         -0.349231  \n",
       "568626         -0.335280  \n",
       "568627         -0.349231  \n",
       "568628          0.271290  \n",
       "568629          1.531994  \n",
       "\n",
       "[568630 rows x 29 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1    284315\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1,X_test1,y_train1,y_test1=train_test_split(X_resampled, y_resampled,test_size=0.30,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdc.fit(X_train1,y_train1)\n",
    "y_pred_smote=rdc.predict(X_test1)\n",
    "dtc.fit(X_train1,y_train1)\n",
    "y_pred_smote1=dtc.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Decison tree\n",
      "Accuracy score:  0.9998886211889395\n",
      "Precision score:  0.99977767116395\n",
      "Recall score:  1.0\n",
      "F1 score:  0.9998888232230733\n",
      "Confusion matrix: \n",
      " [[85130    19]\n",
      " [    0 85440]]\n",
      "Classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85149\n",
      "           1       1.00      1.00      1.00     85440\n",
      "\n",
      "    accuracy                           1.00    170589\n",
      "   macro avg       1.00      1.00      1.00    170589\n",
      "weighted avg       1.00      1.00      1.00    170589\n",
      "\n",
      "For RandomForest Classification:\n",
      "Accuracy score:  0.9978662164617883\n",
      "Precision score:  0.9970670032017575\n",
      "Recall score:  0.9986774344569288\n",
      "F1 score:  0.9978715690746003\n",
      "Confusion matrix: \n",
      " [[84898   251]\n",
      " [  113 85327]]\n",
      "Classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85149\n",
      "           1       1.00      1.00      1.00     85440\n",
      "\n",
      "    accuracy                           1.00    170589\n",
      "   macro avg       1.00      1.00      1.00    170589\n",
      "weighted avg       1.00      1.00      1.00    170589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('For Decison tree')\n",
    "print('Accuracy score: ',accuracy_score(y_test1,y_pred_smote))\n",
    "print('Precision score: ',precision_score(y_test1,y_pred_smote))\n",
    "print('Recall score: ',recall_score(y_test1,y_pred_smote))\n",
    "print('F1 score: ',f1_score(y_test1,y_pred_smote))\n",
    "print('Confusion matrix: \\n',confusion_matrix(y_test1,y_pred_smote))\n",
    "print('Classification_report: \\n',classification_report(y_test1,y_pred_smote))\n",
    "\n",
    "print('For RandomForest Classification:')\n",
    "print('Accuracy score: ',accuracy_score(y_test1,y_pred_smote1))\n",
    "print('Precision score: ',precision_score(y_test1,y_pred_smote1))\n",
    "print('Recall score: ',recall_score(y_test1,y_pred_smote1))\n",
    "print('F1 score: ',f1_score(y_test1,y_pred_smote1))\n",
    "print('Confusion matrix: \\n',confusion_matrix(y_test1,y_pred_smote1))\n",
    "print('Classification_report: \\n',classification_report(y_test1,y_pred_smote1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
